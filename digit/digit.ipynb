{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- ref. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (42000, 785)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "test (28000, 784)\n",
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n",
      "all (70000, 784)\n",
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd, numpy as np\n",
    "pd.set_option(\"display.width\", 80)\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "n_cpus = mp.cpu_count()\n",
    "\n",
    "train_df = pd.read_csv(\"./train.csv\")   # 42000\n",
    "#train_df = pd.read_csv(\"./train.csv\", nrows=10000)\n",
    "test_df = pd.read_csv(\"./test.csv\")   # 28000\n",
    "train_num = train_df.shape[0]\n",
    "test_num = test_df.shape[0]\n",
    "train_x = train_df.drop(['label'], axis=1)\n",
    "train_y = train_df[\"label\"]\n",
    "test_x = test_df\n",
    "all_df = pd.concat((train_x, test_df))\n",
    "\n",
    "dfd = {'train': train_df, 'test': test_df, 'all': all_df}\n",
    "for name,df in dfd.items():\n",
    "    print(name, df.shape)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n",
      "test\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n",
      "None\n",
      "all\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 419.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check data\n",
    "for name,df in dfd.items():\n",
    "    print(name)\n",
    "    print(df.info())\n",
    "    #print(df.describe())   # doesn't show a lot of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Series([], dtype: float64)\n",
      "test\n",
      "Series([], dtype: float64)\n",
      "all\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# check null\n",
    "for name,df in dfd.items():\n",
    "    print(name)\n",
    "    isnull_ratio = df.isnull().sum()/df.isnull().count()\n",
    "    print(isnull_ratio[isnull_ratio != 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# check correlation (takes time)\n",
    "# -> pixel436 has high correlation with label.. so what?\n",
    "# correlations = train_df.astype(float).corr()['label'].sort_values(ascending=False)\n",
    "# print(correlations.head())\n",
    "# print(correlations.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# check skewness (takes time)\n",
    "# -> pixel367 has high skewness, but log/boxcox transform doesn't help\n",
    "# from scipy.stats import skew\n",
    "# skewness = all_df.apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "# print(skewness.head())\n",
    "# print(skewness.tail())\n",
    "# all_df['pixel367'].hist(bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# grid search (takes time)\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "train_x = all_df[:train_num]\n",
    "test_x = all_df[train_num:]\n",
    "\n",
    "# models = []\n",
    "# C_list, gamma_list, degree_list = np.logspace(-2, 0, 3), np.logspace(-3, -1, 3), np.linspace(1, 3, 3)\n",
    "# grid = [\n",
    "#     {'C': C_list, 'kernel': ['poly'], 'gamma': gamma_list, 'degree': degree_list},\n",
    "#     # {'C': C_list, 'kernel': ['sigmoid'], 'gamma': gamma_list},\n",
    "#     # {'C': C_list, 'kernel': ['linear']},\n",
    "#     # {'C': C_list, 'kernel': ['rbf'], 'gamma': gamma_list},\n",
    "#     ]\n",
    "# models.append(('svm', GridSearchCV(SVC(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = [{'n_estimators': [1000], 'max_depth': [6,7,8], 'min_samples_leaf': [2,3], 'max_features' : ['sqrt']}]\n",
    "# models.append(('random_forest', GridSearchCV(RandomForestClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('extra_trees', GridSearchCV(ExtraTreesClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {'n_estimators': [1000], 'learning_rate' : [0.25, 0.5, 0.75]}\n",
    "# models.append(('ada_boost', GridSearchCV(AdaBoostClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {'n_estimators': [1000], 'max_depth': [6,7,8], 'min_samples_leaf': [2,3]}\n",
    "# models.append(('gradient_boosting', GridSearchCV(GradientBoostingClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {'max_iter': [1000], 'tol': [0.001]}\n",
    "# models.append(('perceptron', GridSearchCV(Perceptron(max_iter=1000, tol=0.001), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('sgd_classifier', GridSearchCV(SGDClassifier(max_iter=1000, tol=0.001), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {'n_neighbors': [2,3,4]}\n",
    "# models.append(('k-nearest_neighbors', GridSearchCV(KNeighborsClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {}\n",
    "# models.append(('logistic_regression', GridSerchCV(LogisticRegression(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('gaussian_naive bayes', GridSearchCV(GaussianNB(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('linear_svc', GridSearchCV(LinearSVC(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('decision_tree', GridSearchCV(DecisionTreeClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "\n",
    "# params = {}\n",
    "# for name,model in models:\n",
    "#     model.fit(train_x, train_y)\n",
    "#     print(name, model.best_score_, model.best_params_)\n",
    "#     params[name] = model.best_params_\n",
    "#     # results = model.cv_results_\n",
    "#     # for mean, std, params in zip(results['mean_test_score'], results['std_test_score'], results['params']):\n",
    "#     #     print(\"{:0.3f} (+/-{:0.03f} for {}\".format(mean, std, params))\n",
    "\n",
    "# from the result of nrows=20000\n",
    "params = {\n",
    "    'k-nearest_neighbors': {'n_neighbors': 3},\n",
    "    'sgd_classifier': {'max_iter': 1000, 'tol': 0.001},\n",
    "    'perceptron': {'max_iter': 1000, 'tol': 0.001},\n",
    "    'gradient_boosting': {'max_depth': 6, 'min_samples_leaf': 3, 'n_estimators': 1000},\n",
    "    'ada_boost': {'learning_rate': 0.25, 'n_estimators': 1000},\n",
    "    'extra_trees': {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 1000},\n",
    "    'random_forest': {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 1000},\n",
    "    'svm': {'C': 0.01, 'degree': 2.0, 'gamma': 0.001, 'kernel': 'poly'},\n",
    "    'logistic_regression': {},\n",
    "    'gaussian_naive bayes': {},\n",
    "    'linear_svc': {},\n",
    "    'decision_tree': {},\n",
    "    }\n",
    "\n",
    "svm_model = SVC(**params['svm'])\n",
    "# bagging_svm_model = BaggingClassifier(base_estimator=clone(svm_model),\n",
    "#                                       n_estimators=10, max_samples=0.9, max_features=0.2)\n",
    "et_model = ExtraTreesClassifier(**params['extra_trees'])\n",
    "# bagging_et_model = BaggingClassifier(base_estimator=clone(et_model),\n",
    "#                                      n_estimators=10, max_samples=0.9, max_features=0.2)\n",
    "knn_model = KNeighborsClassifier(**params['k-nearest_neighbors'])\n",
    "# bagging_knn_model = BaggingClassifier(base_estimator=clone(knn_model),\n",
    "#                                       n_estimators=10, max_samples=0.9, max_features=0.2)\n",
    "lr_model = LogisticRegression(**params['logistic_regression'])\n",
    "# stacking_model = StackingClassifier(classifiers=[clone(svm_model), clone(et_model), clone(knn_model)],\n",
    "#                                     meta_classifier=clone(lr_model))\n",
    "models = [\n",
    "    ('svm', svm_model),\n",
    "    # ('bagging_svm', bagging_svm_model),\n",
    "    ('extra_trees', et_model),\n",
    "    # ('bagging_extra_trees', bagging_et_model),\n",
    "    ('random_forest', RandomForestClassifier(**params['random_forest'])),\n",
    "    ('ada_boost', AdaBoostClassifier(**params['ada_boost'])),\n",
    "    ('gradient_boosting', GradientBoostingClassifier(**params['gradient_boosting'])),\n",
    "    ('perceptron', Perceptron(**params['perceptron'])),\n",
    "    ('sgd_classifier', SGDClassifier(**params['sgd_classifier'])),\n",
    "    ('k-nearest_neighbors', knn_model),\n",
    "    # ('bagging_k-nearest_neighbors', bagging_knn_model),\n",
    "    ('logistic_regression', lr_model),\n",
    "    ('gaussian_naive bayes', GaussianNB(**params['gaussian_naive bayes'])),\n",
    "    ('linear_svc', LinearSVC(**params['linear_svc'])),\n",
    "    ('decision_tree', DecisionTreeClassifier(**params['decision_tree'])),\n",
    "    # ('stacking', stacking_model),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from multiprocessing import Manager\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "# k_fold = KFold(n_splits=3)\n",
    "# with Manager() as manager:\n",
    "#     results = manager.list()\n",
    "#     def validate_one_model(name, model):\n",
    "#          # Multiprocessing-backed parallel loops cannot be nested\n",
    "#          scores = cross_validate(model, train_x, train_y, cv=k_fold, scoring='accuracy')\n",
    "#          result = {}\n",
    "#          result['model'] = name\n",
    "#          result['test_mean'] = np.mean(scores['test_score'])\n",
    "#          result['test_std'] = np.std(scores['test_score'])\n",
    "#          result['train_mean'] = np.mean(scores['train_score'])\n",
    "#          result['train_std'] = np.std(scores['train_score'])\n",
    "#          results.append(result)\n",
    "#     Parallel(n_jobs=n_cpus)(delayed(validate_one_model)(name, model) for name,model in models)\n",
    "#     results_merged = {'model': [], 'test_mean': [], 'test_std': [], 'train_mean': [], 'train_std': []}\n",
    "#     for result in results:\n",
    "#         for k,v in result.items():\n",
    "#             results_merged[k].append(v)\n",
    "#     print(pd.DataFrame(results_merged).sort_values(by='test_mean', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# learn, predict and report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.externals.joblib import Parallel, delayed, dump\n",
    "test_id = np.arange(1, test_num+1)\n",
    "# results = {}\n",
    "# def process_one_model(name, model):\n",
    "#     model.fit(train_x, train_y)\n",
    "#     predict_y = model.predict(train_x)\n",
    "#     output = model.predict(test_x)\n",
    "#     results[name] = output\n",
    "#     print(output[:20])\n",
    "#     submit = pd.DataFrame(data={'ImageId':test_id, 'Label':output})\n",
    "#     submit.to_csv('{}_submit.csv'.format(name), index=False)\n",
    "#     #dump(model, '{}.learn'.format(name))\n",
    "#     print(name)\n",
    "#     print(confusion_matrix(train_y, predict_y))\n",
    "#     print(classification_report(train_y, predict_y))\n",
    "# Parallel(n_jobs=n_cpus)(delayed(process_one_model)(name, model) for name,model in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageId,Label\r\n",
      "1,2\r\n",
      "2,0\r\n",
      "3,9\r\n",
      "4,9\r\n",
      "5,3\r\n",
      "6,7\r\n",
      "7,0\r\n",
      "8,3\r\n",
      "9,0\r\n"
     ]
    }
   ],
   "source": [
    "!head svm_submit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning..\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \n",
      "         acc      loss   val_acc  val_loss\n",
      "11  0.987196  0.039662  0.987381  0.037124\n",
      "12  0.988201  0.038215  0.988810  0.033280\n",
      "13  0.989312  0.034392  0.988333  0.035691\n",
      "14  0.989339  0.033950  0.987381  0.033301\n",
      "15  0.989974  0.031808  0.987619  0.035447\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDCncRUTK0P8HhfUuv/0WsVcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3137695588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "\n",
      "   32/28000 [..............................] - ETA: 80s\n",
      " 1024/28000 [>.............................] - ETA: 4s \n",
      " 1600/28000 [>.............................] - ETA: 3s\n",
      " 2304/28000 [=>............................] - ETA: 3s\n",
      " 3040/28000 [==>...........................] - ETA: 2s\n",
      " 3744/28000 [===>..........................] - ETA: 2s\n",
      " 4352/28000 [===>..........................] - ETA: 2s\n",
      " 5056/28000 [====>.........................] - ETA: 2s\n",
      " 5760/28000 [=====>........................] - ETA: 2s\n",
      " 6432/28000 [=====>........................] - ETA: 2s\n",
      " 7040/28000 [======>.......................] - ETA: 2s\n",
      " 7744/28000 [=======>......................] - ETA: 2s\n",
      " 8480/28000 [========>.....................] - ETA: 2s\n",
      " 9120/28000 [========>.....................] - ETA: 2s\n",
      " 9728/28000 [=========>....................] - ETA: 2s\n",
      "10432/28000 [==========>...................] - ETA: 1s\n",
      "11136/28000 [==========>...................] - ETA: 1s\n",
      "11808/28000 [===========>..................] - ETA: 1s\n",
      "12448/28000 [============>.................] - ETA: 1s\n",
      "13120/28000 [=============>................] - ETA: 1s\n",
      "13760/28000 [=============>................] - ETA: 1s\n",
      "14400/28000 [==============>...............] - ETA: 1s\n",
      "15168/28000 [===============>..............] - ETA: 1s\n",
      "15808/28000 [===============>..............] - ETA: 1s\n",
      "16448/28000 [================>.............] - ETA: 1s\n",
      "17088/28000 [=================>............] - ETA: 1s\n",
      "17728/28000 [=================>............] - ETA: 1s\n",
      "18400/28000 [==================>...........] - ETA: 1s\n",
      "19104/28000 [===================>..........] - ETA: 1s\n",
      "19872/28000 [====================>.........] - ETA: 1s\n",
      "20544/28000 [=====================>........] - ETA: 1s\n",
      "21216/28000 [=====================>........] - ETA: 1s\n",
      "21856/28000 [======================>.......] - ETA: 0s\n",
      "22592/28000 [=======================>......] - ETA: 0s\n",
      "23264/28000 [=======================>......] - ETA: 0s\n",
      "23904/28000 [========================>.....] - ETA: 0s\n",
      "24576/28000 [=========================>....] - ETA: 0s\n",
      "25280/28000 [==========================>...] - ETA: 0s\n",
      "25952/28000 [==========================>...] - ETA: 0s\n",
      "26656/28000 [===========================>..] - ETA: 0s\n",
      "27392/28000 [============================>.] - ETA: 0s\n",
      "28000/28000 [==============================] - ETA: 0s\n",
      "\n",
      "predict:  [2 0 9 9 3 7 0 3 0 3 5 7 4 0 4 3 3 1 9 0]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "trainX = train_x.values.reshape(len(train_x.index), 28, 28, 1).astype('float32')/255\n",
    "testX = test_x.values.reshape(len(test_x.index), 28, 28, 1).astype('float32')/255\n",
    "trainY = train_y.values\n",
    "# trainY = np_utils.to_categorical(train_y.values, num_classes=10)   # required for categorical_crossentropy\n",
    "\n",
    "keras_model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(rate=0.25),\n",
    "    Flatten(),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(units=10, activation='softmax'),\n",
    "])\n",
    "keras_model.compile(loss='sparse_categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "# keras_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])   # worse\n",
    "# print(keras_model.summary())\n",
    "\n",
    "print('learning..')\n",
    "class PrintProgress(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(epoch, end=' ')\n",
    "history = keras_model.fit(trainX, trainY, epochs=20, batch_size=128, validation_split=0.1,\n",
    "                          callbacks=[EarlyStopping(patience=3), PrintProgress()], verbose=0)\n",
    "print()\n",
    "hist_df = pd.DataFrame({'loss': history.history['loss'], 'acc': history.history['acc'],\n",
    "                        'val_loss': history.history['val_loss'], 'val_acc': history.history['val_acc']})\n",
    "print(hist_df.tail())\n",
    "hist_df.plot()\n",
    "plt.show()\n",
    "\n",
    "print('predicting..')\n",
    "output = keras_model.predict_classes(testX)\n",
    "print()\n",
    "print('predict: ', output[:20])\n",
    "submit = pd.DataFrame(data={'ImageId':test_id, 'Label':output})\n",
    "submit.to_csv('nn_keras_submit.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!head nn_keras_submit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# neural network with tensorflow (skflow -> contrib.learn -> estimator)\n",
    "# import tensorflow as tf\n",
    "# trainX = train_x/255\n",
    "# testX = test_x/255\n",
    "# trainY = train_y\n",
    "# feature_columns = [tf.feature_column.numeric_column(k) for k in train_x.columns]\n",
    "# tf_model = tf.estimator.DNNClassifier(hidden_units=[1000], n_classes=10, feature_columns=feature_columns)\n",
    "# input_fn_train = tf.estimator.inputs.pandas_input_fn(x=trainX, y=trainY, shuffle=False)\n",
    "# tf_model.train(input_fn=input_fn_train, steps=100)\n",
    "# tf_model.evaluate(input_fn=input_fn_train, steps=10)\n",
    "# #scores = cross_validate(tf_model, train_x, train_y, cv=k_fold, scoring='accuracy')   # throws an error\n",
    "# input_fn_predict = tf.estimator.inputs.pandas_input_fn(x=testX, shuffle=False)\n",
    "# generator = tf_model.predict(input_fn=input_fn_predict)\n",
    "# output = [d['class_ids'][0] for d in generator]\n",
    "# print(output[:20])\n",
    "# submit = pd.DataFrame(data={'ImageId':test_id, 'Label':output})\n",
    "# submit.to_csv('nn_tensor_submit.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "digit.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
