{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- ref. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (42000, 785)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "test (28000, 784)\n",
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n",
      "all (70000, 784)\n",
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd, numpy as np\n",
    "pd.set_option(\"display.width\", 80)\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "n_cpus = mp.cpu_count()\n",
    "\n",
    "train_df = pd.read_csv(\"./train.csv\")   # 42000\n",
    "# train_df = pd.read_csv(\"./train.csv\", nrows=1000)\n",
    "test_df = pd.read_csv(\"./test.csv\")   # 28000\n",
    "train_num = train_df.shape[0]\n",
    "test_num = test_df.shape[0]\n",
    "train_x = train_df.drop(['label'], axis=1)\n",
    "train_y = train_df[\"label\"]\n",
    "test_x = test_df\n",
    "all_df = pd.concat((train_x, test_df))\n",
    "\n",
    "dfd = {'train': train_df, 'test': test_df, 'all': all_df}\n",
    "for name,df in dfd.items():\n",
    "    print(name, df.shape)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n",
      "test\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n",
      "None\n",
      "all\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 419.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check data\n",
    "for name,df in dfd.items():\n",
    "    print(name)\n",
    "    print(df.info())\n",
    "    #print(df.describe())   # doesn't show a lot of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    }
   ],
   "source": [
    "# check null\n",
    "for name,df in dfd.items():\n",
    "    print(name)\n",
    "    isnull_ratio = df.isnull().sum()/df.isnull().count()\n",
    "    print(isnull_ratio[isnull_ratio != 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# check correlation (takes time)\n",
    "# -> pixel436 has high correlation with label.. so what?\n",
    "# correlations = train_df.astype(float).corr()['label'].sort_values(ascending=False)\n",
    "# print(correlations.head())\n",
    "# print(correlations.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# check skewness (takes time)\n",
    "# -> pixel367 has high skewness, but log/boxcox transform doesn't help\n",
    "# from scipy.stats import skew\n",
    "# skewness = all_df.apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "# print(skewness.head())\n",
    "# print(skewness.tail())\n",
    "# all_df['pixel367'].hist(bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# grid search (takes time)\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "train_x = all_df[:train_num]\n",
    "test_x = all_df[train_num:]\n",
    "\n",
    "# models = []\n",
    "# C_list, gamma_list, degree_list = np.logspace(-2, 0, 3), np.logspace(-3, -1, 3), np.linspace(1, 3, 3)\n",
    "# grid = [\n",
    "#     {'C': C_list, 'kernel': ['poly'], 'gamma': gamma_list, 'degree': degree_list},\n",
    "#     # {'C': C_list, 'kernel': ['sigmoid'], 'gamma': gamma_list},\n",
    "#     # {'C': C_list, 'kernel': ['linear']},\n",
    "#     # {'C': C_list, 'kernel': ['rbf'], 'gamma': gamma_list},\n",
    "#     ]\n",
    "# models.append(('svm', GridSearchCV(SVC(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = [{'n_estimators': [1000], 'max_depth': [6,7,8], 'min_samples_leaf': [2,3], 'max_features' : ['sqrt']}]\n",
    "# models.append(('random_forest', GridSearchCV(RandomForestClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('extra_trees', GridSearchCV(ExtraTreesClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {'n_estimators': [1000], 'learning_rate' : [0.25, 0.5, 0.75]}\n",
    "# models.append(('ada_boost', GridSearchCV(AdaBoostClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {'n_estimators': [1000], 'max_depth': [6,7,8], 'min_samples_leaf': [2,3]}\n",
    "# models.append(('gradient_boosting', GridSearchCV(GradientBoostingClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {'max_iter': [1000], 'tol': [0.001]}\n",
    "# models.append(('perceptron', GridSearchCV(Perceptron(max_iter=1000, tol=0.001), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('sgd_classifier', GridSearchCV(SGDClassifier(max_iter=1000, tol=0.001), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {'n_neighbors': [2,3,4]}\n",
    "# models.append(('k-nearest_neighbors', GridSearchCV(KNeighborsClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# grid = {}\n",
    "# models.append(('logistic_regression', GridSerchCV(LogisticRegression(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('gaussian_naive bayes', GridSearchCV(GaussianNB(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('linear_svc', GridSearchCV(LinearSVC(), grid, cv=3, n_jobs=n_cpus)))\n",
    "# models.append(('decision_tree', GridSearchCV(DecisionTreeClassifier(), grid, cv=3, n_jobs=n_cpus)))\n",
    "\n",
    "# params = {}\n",
    "# for name,model in models:\n",
    "#     model.fit(train_x, train_y)\n",
    "#     print(name, model.best_score_, model.best_params_)\n",
    "#     params[name] = model.best_params_\n",
    "#     # results = model.cv_results_\n",
    "#     # for mean, std, params in zip(results['mean_test_score'], results['std_test_score'], results['params']):\n",
    "#     #     print(\"{:0.3f} (+/-{:0.03f} for {}\".format(mean, std, params))\n",
    "\n",
    "# from the result of nrows=20000\n",
    "params = {\n",
    "    'k-nearest_neighbors': {'n_neighbors': 3},\n",
    "    'sgd_classifier': {'max_iter': 1000, 'tol': 0.001},\n",
    "    'perceptron': {'max_iter': 1000, 'tol': 0.001},\n",
    "    'gradient_boosting': {'max_depth': 6, 'min_samples_leaf': 3, 'n_estimators': 1000},\n",
    "    'ada_boost': {'learning_rate': 0.25, 'n_estimators': 1000},\n",
    "    'extra_trees': {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 1000},\n",
    "    'random_forest': {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 1000},\n",
    "    'svm': {'C': 0.01, 'degree': 2.0, 'gamma': 0.001, 'kernel': 'poly'},\n",
    "    'logistic_regression': {},\n",
    "    'gaussian_naive bayes': {},\n",
    "    'linear_svc': {},\n",
    "    'decision_tree': {},\n",
    "    }\n",
    "\n",
    "svm_model = SVC(**params['svm'])\n",
    "bagging_svm_model = BaggingClassifier(base_estimator=clone(svm_model),\n",
    "                                      n_estimators=10, max_samples=0.9, max_features=0.2)\n",
    "et_model = ExtraTreesClassifier(**params['extra_trees'])\n",
    "bagging_et_model = BaggingClassifier(base_estimator=clone(et_model),\n",
    "                                     n_estimators=10, max_samples=0.9, max_features=0.2)\n",
    "knn_model = KNeighborsClassifier(**params['k-nearest_neighbors'])\n",
    "bagging_knn_model = BaggingClassifier(base_estimator=clone(knn_model),\n",
    "                                      n_estimators=10, max_samples=0.9, max_features=0.2)\n",
    "lr_model = LogisticRegression(**params['logistic_regression'])\n",
    "stacking_model = StackingClassifier(classifiers=[clone(svm_model), clone(et_model), clone(knn_model)],\n",
    "                                    meta_classifier=clone(lr_model))\n",
    "models = [\n",
    "    ('svm', svm_model),\n",
    "    # ('bagging_svm', bagging_svm_model),\n",
    "    ('extra_trees', et_model),\n",
    "    # ('bagging_extra_trees', bagging_et_model),\n",
    "    ('random_forest', RandomForestClassifier(**params['random_forest'])),\n",
    "    ('ada_boost', AdaBoostClassifier(**params['ada_boost'])),\n",
    "    ('gradient_boosting', GradientBoostingClassifier(**params['gradient_boosting'])),\n",
    "    ('perceptron', Perceptron(**params['perceptron'])),\n",
    "    ('sgd_classifier', SGDClassifier(**params['sgd_classifier'])),\n",
    "    ('k-nearest_neighbors', knn_model),\n",
    "    # ('bagging_k-nearest_neighbors', bagging_knn_model),\n",
    "    ('logistic_regression', lr_model),\n",
    "    ('gaussian_naive bayes', GaussianNB(**params['gaussian_naive bayes'])),\n",
    "    ('linear_svc', LinearSVC(**params['linear_svc'])),\n",
    "    ('decision_tree', DecisionTreeClassifier(**params['decision_tree'])),\n",
    "    # ('stacking', stacking_model),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   model  test_mean  test_std  train_mean  train_std\n",
      "7                    svm   0.974429  0.001222    1.000000   0.000000\n",
      "11     gradient_boosting   0.966881  0.000897    1.000000   0.000000\n",
      "9    k-nearest_neighbors   0.965429  0.001125    0.981595   0.000276\n",
      "4          random_forest   0.926714  0.002734    0.942488   0.001532\n",
      "3            extra_trees   0.916786  0.003062    0.929190   0.000992\n",
      "10   logistic_regression   0.901405  0.000994    0.946464   0.000582\n",
      "1         sgd_classifier   0.875095  0.009214    0.897393   0.013037\n",
      "0             perceptron   0.858262  0.006284    0.874333   0.004659\n",
      "6             linear_svc   0.850429  0.004476    0.880464   0.002844\n",
      "5          decision_tree   0.845929  0.000498    1.000000   0.000000\n",
      "8              ada_boost   0.737548  0.032553    0.743036   0.027985\n",
      "2   gaussian_naive bayes   0.562619  0.006971    0.565512   0.007930\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from multiprocessing import Manager\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "k_fold = KFold(n_splits=3)\n",
    "with Manager() as manager:\n",
    "    results = manager.list()\n",
    "    def validate_one_model(name, model):\n",
    "         # Multiprocessing-backed parallel loops cannot be nested\n",
    "         scores = cross_validate(model, train_x, train_y, cv=k_fold, scoring='accuracy')\n",
    "         result = {}\n",
    "         result['model'] = name\n",
    "         result['test_mean'] = np.mean(scores['test_score'])\n",
    "         result['test_std'] = np.std(scores['test_score'])\n",
    "         result['train_mean'] = np.mean(scores['train_score'])\n",
    "         result['train_std'] = np.std(scores['train_score'])\n",
    "         results.append(result)\n",
    "    Parallel(n_jobs=n_cpus)(delayed(validate_one_model)(name, model) for name,model in models)\n",
    "    results_merged = {'model': [], 'test_mean': [], 'test_std': [], 'train_mean': [], 'train_std': []}\n",
    "    for result in results:\n",
    "        for k,v in result.items():\n",
    "            results_merged[k].append(v)\n",
    "    print(pd.DataFrame(results_merged).sort_values(by='test_mean', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      4132\n",
      "          1       1.00      1.00      1.00      4684\n",
      "          2       1.00      1.00      1.00      4177\n",
      "          3       1.00      1.00      1.00      4351\n",
      "          4       1.00      1.00      1.00      4072\n",
      "          5       1.00      1.00      1.00      3795\n",
      "          6       1.00      1.00      1.00      4137\n",
      "          7       1.00      1.00      1.00      4401\n",
      "          8       1.00      1.00      1.00      4063\n",
      "          9       1.00      1.00      1.00      4188\n",
      "\n",
      "avg / total       1.00      1.00      1.00     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4132    0    0    0    0    0    0    0    0    0]\n",
      " [   0 4684    0    0    0    0    0    0    0    0]\n",
      " [   0    0 4177    0    0    0    0    0    0    0]\n",
      " [   0    0    0 4351    0    0    0    0    0    0]\n",
      " [   0    0    0    0 4072    0    0    0    0    0]\n",
      " [   0    0    0    0    0 3795    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4137    0    0    0]\n",
      " [   0    0    0    0    0    0    0 4401    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4063    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4188]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      4132\n",
      "          1       0.97      1.00      0.99      4684\n",
      "          2       0.99      0.98      0.99      4177\n",
      "          3       0.98      0.98      0.98      4351\n",
      "          4       0.99      0.98      0.98      4072\n",
      "          5       0.98      0.98      0.98      3795\n",
      "          6       0.99      0.99      0.99      4137\n",
      "          7       0.98      0.98      0.98      4401\n",
      "          8       1.00      0.96      0.98      4063\n",
      "          9       0.97      0.98      0.98      4188\n",
      "\n",
      "avg / total       0.98      0.98      0.98     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4122    0    1    0    0    3    6    0    0    0]\n",
      " [   0 4672    4    0    1    0    0    4    1    2]\n",
      " [  17   20 4107    3    1    1    1   23    2    2]\n",
      " [   4    5   20 4265    0   25    0   11   11   10]\n",
      " [   3   29    0    0 3997    0    5    1    0   37]\n",
      " [   6    2    2   29    2 3721   23    0    1    9]\n",
      " [  14    5    0    0    4   10 4104    0    0    0]\n",
      " [   1   35   11    0    3    0    0 4328    0   23]\n",
      " [  15   28    7   31   11   23    7    5 3913   23]\n",
      " [   9    6    1   19   28    5    2   27    2 4089]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-nearest_neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      4132\n",
      "          1       0.98      0.99      0.98      4684\n",
      "          2       0.94      0.92      0.93      4177\n",
      "          3       0.92      0.91      0.91      4351\n",
      "          4       0.94      0.95      0.94      4072\n",
      "          5       0.92      0.90      0.91      3795\n",
      "          6       0.96      0.97      0.97      4137\n",
      "          7       0.95      0.95      0.95      4401\n",
      "          8       0.89      0.90      0.90      4063\n",
      "          9       0.91      0.91      0.91      4188\n",
      "\n",
      "avg / total       0.94      0.94      0.94     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4077    0    3    4    4    9   13    0   21    1]\n",
      " [   0 4617   10   10    1    6    5    3   29    3]\n",
      " [  13   16 3851   56   37   16   32   39  110    7]\n",
      " [  11    7   96 3972    5   94   12   27   83   44]\n",
      " [   4   15   18    6 3849    6   19   11   36  108]\n",
      " [  25    6   23  112   32 3397   54    8   99   39]\n",
      " [  23    3   15    1   12   45 4022    0   15    1]\n",
      " [   8   11   46    7   27    6    3 4173   11  109]\n",
      " [  28   50   30   98   22   83   25   16 3659   52]\n",
      " [  12   10    7   65   95   33    0  115   44 3807]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.92      0.87      4132\n",
      "          1       0.82      0.98      0.89      4684\n",
      "          2       0.83      0.44      0.57      4177\n",
      "          3       0.83      0.71      0.77      4351\n",
      "          4       0.75      0.87      0.81      4072\n",
      "          5       0.79      0.63      0.70      3795\n",
      "          6       0.63      0.91      0.74      4137\n",
      "          7       0.89      0.82      0.85      4401\n",
      "          8       0.72      0.75      0.73      4063\n",
      "          9       0.75      0.67      0.71      4188\n",
      "\n",
      "avg / total       0.78      0.77      0.77     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3820    0   28    4   10   99  148    1   15    7]\n",
      " [   0 4591    9   11    5   15    7   15   27    4]\n",
      " [ 164  343 1828   99   99   65 1323   58  178   20]\n",
      " [ 215  120   42 3096   11  219  142   72  364   70]\n",
      " [  26   20   57   15 3529   32  123   36   82  152]\n",
      " [ 208   59   22  259   37 2403  314    9  357  127]\n",
      " [  56   50   64    4  101   80 3755    2   25    0]\n",
      " [  42   14   53   17  127   11    0 3609   21  507]\n",
      " [  53  378   29  148   35  104  155   19 3064   78]\n",
      " [  51   38   58   69  728   20    3  253  146 2822]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada_boost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      4132\n",
      "          1       1.00      1.00      1.00      4684\n",
      "          2       1.00      1.00      1.00      4177\n",
      "          3       1.00      1.00      1.00      4351\n",
      "          4       1.00      1.00      1.00      4072\n",
      "          5       1.00      1.00      1.00      3795\n",
      "          6       1.00      1.00      1.00      4137\n",
      "          7       1.00      1.00      1.00      4401\n",
      "          8       1.00      1.00      1.00      4063\n",
      "          9       1.00      1.00      1.00      4188\n",
      "\n",
      "avg / total       1.00      1.00      1.00     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4132    0    0    0    0    0    0    0    0    0]\n",
      " [   0 4684    0    0    0    0    0    0    0    0]\n",
      " [   0    0 4177    0    0    0    0    0    0    0]\n",
      " [   0    0    0 4351    0    0    0    0    0    0]\n",
      " [   0    0    0    0 4072    0    0    0    0    0]\n",
      " [   0    0    0    0    0 3795    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4137    0    0    0]\n",
      " [   0    0    0    0    0    0    0 4401    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4063    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4188]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.95      0.96      4132\n",
      "          1       0.96      0.98      0.97      4684\n",
      "          2       0.72      0.94      0.81      4177\n",
      "          3       0.81      0.89      0.85      4351\n",
      "          4       0.92      0.89      0.91      4072\n",
      "          5       0.78      0.87      0.82      3795\n",
      "          6       0.95      0.95      0.95      4137\n",
      "          7       0.65      0.98      0.78      4401\n",
      "          8       0.95      0.38      0.54      4063\n",
      "          9       0.90      0.51      0.65      4188\n",
      "\n",
      "avg / total       0.86      0.84      0.83     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3936    0   56   20    6   48   39   19    6    2]\n",
      " [   0 4595   41   21    4    2    3   11    7    0]\n",
      " [   6   21 3922   73   38   12   31   66    5    3]\n",
      " [  12   10  179 3885    7  149   14   64   11   20]\n",
      " [   1   17   43   14 3632   24   26  196    7  112]\n",
      " [  38    6  109  158   39 3289   57   45   35   19]\n",
      " [  20    2  109    3   18   58 3912    7    8    0]\n",
      " [   0    8   31   15   13    3    3 4293    3   32]\n",
      " [  61   92  937  515   40  580   32  225 1541   40]\n",
      " [   9   11   53   96  156   57    2 1653    6 2145]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_svc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      4132\n",
      "          1       1.00      1.00      1.00      4684\n",
      "          2       1.00      1.00      1.00      4177\n",
      "          3       1.00      1.00      1.00      4351\n",
      "          4       1.00      1.00      1.00      4072\n",
      "          5       1.00      1.00      1.00      3795\n",
      "          6       1.00      1.00      1.00      4137\n",
      "          7       1.00      1.00      1.00      4401\n",
      "          8       1.00      1.00      1.00      4063\n",
      "          9       1.00      1.00      1.00      4188\n",
      "\n",
      "avg / total       1.00      1.00      1.00     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4132    0    0    0    0    0    0    0    0    0]\n",
      " [   0 4684    0    0    0    0    0    0    0    0]\n",
      " [   0    0 4177    0    0    0    0    0    0    0]\n",
      " [   0    0    0 4351    0    0    0    0    0    0]\n",
      " [   0    0    0    0 4072    0    0    0    0    0]\n",
      " [   0    0    0    0    0 3795    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4137    0    0    0]\n",
      " [   0    0    0    0    0    0    0 4401    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4063    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4188]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98      4132\n",
      "          1       0.95      0.98      0.96      4684\n",
      "          2       0.94      0.94      0.94      4177\n",
      "          3       0.94      0.91      0.92      4351\n",
      "          4       0.94      0.92      0.93      4072\n",
      "          5       0.96      0.92      0.94      3795\n",
      "          6       0.96      0.97      0.96      4137\n",
      "          7       0.95      0.93      0.94      4401\n",
      "          8       0.93      0.91      0.92      4063\n",
      "          9       0.87      0.92      0.89      4188\n",
      "\n",
      "avg / total       0.94      0.94      0.94     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4053    0    3    2    4    4   22    1   41    2]\n",
      " [   0 4595   22   17    5    6   13    8   11    7]\n",
      " [  16   23 3911   26   48    2   34   71   32   14]\n",
      " [  10   34   87 3967   13   61   12   47   65   55]\n",
      " [   7    7    8    0 3760    3   32   11   20  224]\n",
      " [  26   50    5   81   17 3488   40    9   33   46]\n",
      " [  25   16    2    0   18   33 4021    1   21    0]\n",
      " [   5   42   76    3   36    0    0 4076   17  146]\n",
      " [   9   71   21   71   23   22   23    9 3717   97]\n",
      " [  24   22   15   73   84    9    3   73   44 3841]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      4132\n",
      "          1       0.91      0.98      0.95      4684\n",
      "          2       0.94      0.91      0.93      4177\n",
      "          3       0.91      0.90      0.91      4351\n",
      "          4       0.93      0.92      0.92      4072\n",
      "          5       0.96      0.88      0.92      3795\n",
      "          6       0.94      0.97      0.96      4137\n",
      "          7       0.92      0.92      0.92      4401\n",
      "          8       0.93      0.89      0.91      4063\n",
      "          9       0.87      0.89      0.88      4188\n",
      "\n",
      "avg / total       0.93      0.93      0.93     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4053    0    3    0    3    1   34    3   35    0]\n",
      " [   0 4608   15   20    3    6    9   11    8    4]\n",
      " [  27   48 3814   34   54    4   50   99   32   15]\n",
      " [  18   49   83 3933    8   69   15   56   67   53]\n",
      " [   7   27   12    1 3732    1   37   17   24  214]\n",
      " [  48   65    8  146   34 3351   49   22   30   42]\n",
      " [  40   25    5    0   19   21 4007    7   13    0]\n",
      " [  11   92   76    4   39    0    1 4054   16  108]\n",
      " [   8  110   21  109   28   33   33   14 3606  101]\n",
      " [  30   32   19   70  109    8    6  140   39 3735]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_trees\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.87      0.81      4132\n",
      "          1       0.78      0.95      0.86      4684\n",
      "          2       0.88      0.26      0.40      4177\n",
      "          3       0.70      0.36      0.48      4351\n",
      "          4       0.83      0.15      0.25      4072\n",
      "          5       0.64      0.06      0.10      3795\n",
      "          6       0.59      0.95      0.73      4137\n",
      "          7       0.90      0.32      0.47      4401\n",
      "          8       0.30      0.64      0.41      4063\n",
      "          9       0.39      0.94      0.55      4188\n",
      "\n",
      "avg / total       0.68      0.56      0.51     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3607    6   20   14    6    7  241    2  158   71]\n",
      " [   0 4456   11   22    3    9   56    2   89   36]\n",
      " [ 352  121 1066  431   21   32 1184   15  893   62]\n",
      " [ 187  245   29 1581    3    7  331   34 1543  391]\n",
      " [  89   42   31   25  602   23  512   21  804 1923]\n",
      " [ 381  117   20   88   19  213  304    8 2263  382]\n",
      " [  33   55   13    4    3   13 3950    0   61    5]\n",
      " [  15   36    4   37   30    5   18 1404  154 2698]\n",
      " [  56  577    8   42   14   20  101    5 2584  656]\n",
      " [  19   40   13    7   23    2    5   61   79 3939]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_naive bayes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      4132\n",
      "          1       0.98      0.95      0.97      4684\n",
      "          2       0.93      0.87      0.90      4177\n",
      "          3       0.72      0.94      0.82      4351\n",
      "          4       0.95      0.89      0.92      4072\n",
      "          5       0.89      0.81      0.85      3795\n",
      "          6       0.93      0.97      0.95      4137\n",
      "          7       0.84      0.95      0.89      4401\n",
      "          8       0.86      0.78      0.82      4063\n",
      "          9       0.91      0.75      0.82      4188\n",
      "\n",
      "avg / total       0.90      0.89      0.89     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4029    0   12   21    3   13   29    4   17    4]\n",
      " [   0 4453   21   76    1   25   10   17   79    2]\n",
      " [  18   11 3623  237   24   27   92   60   79    6]\n",
      " [   7    3   78 4106    0   64   18   24   31   20]\n",
      " [   8   17   30   59 3611    8   55   77   72  135]\n",
      " [  53    8   22  373   30 3075   45   24  120   45]\n",
      " [  22    2   17    0    9   68 4005    2   10    2]\n",
      " [  20    3   29   81   20   10    4 4191    7   36]\n",
      " [  25   32   38  553    8  132   31   47 3155   42]\n",
      " [  20    7   32  217  110   37    1  535   90 3139]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd_classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95      4132\n",
      "          1       0.96      0.97      0.96      4684\n",
      "          2       0.98      0.73      0.84      4177\n",
      "          3       0.84      0.86      0.85      4351\n",
      "          4       0.88      0.94      0.91      4072\n",
      "          5       0.74      0.86      0.80      3795\n",
      "          6       0.96      0.93      0.94      4137\n",
      "          7       0.91      0.93      0.92      4401\n",
      "          8       0.74      0.82      0.78      4063\n",
      "          9       0.91      0.78      0.84      4188\n",
      "\n",
      "avg / total       0.89      0.88      0.88     42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4040    0    1   15   12   25    8    4   25    2]\n",
      " [   1 4538    5   18    3   46    4    9   52    8]\n",
      " [  84   74 3057  247   82   84   56   72  416    5]\n",
      " [  19   17   22 3721    8  251    6   24  230   53]\n",
      " [   8    7    3    6 3824   20   13   14   84   93]\n",
      " [  51    5    2  232   39 3267   67    9   88   35]\n",
      " [  54   11    8    4   51  114 3864   10   21    0]\n",
      " [   9   15   14   28   38   31    1 4095   62  108]\n",
      " [  45   50    7  106   30  410   23   21 3346   25]\n",
      " [  19    8    3   66  271  152    1  244  178 3246]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perceptron\n"
     ]
    }
   ],
   "source": [
    "# learn, predict and report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.externals.joblib import Parallel, delayed, dump\n",
    "test_id = np.arange(1, test_num+1)\n",
    "results = {}\n",
    "def process_one_model(name, model):\n",
    "    model.fit(train_x, train_y)\n",
    "    predict_y = model.predict(train_x)\n",
    "    output = model.predict(test_x)\n",
    "    results[name] = output\n",
    "    submit = pd.DataFrame(data={'ImageId':test_id, 'Label':output})\n",
    "    submit.to_csv('{}_submit.csv'.format(name), index=False)\n",
    "    #dump(model, '{}.learn'.format(name))\n",
    "    print(name)\n",
    "    print(confusion_matrix(train_y, predict_y))\n",
    "    print(classification_report(train_y, predict_y))\n",
    "Parallel(n_jobs=n_cpus)(delayed(process_one_model)(name, model) for name,model in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# neural network with tensorflow (skflow -> contrib.learn -> estimator)\n",
    "# import tensorflow as tf\n",
    "# feature_columns = [tf.feature_column.numeric_column(k) for k in train_x.columns]\n",
    "# tf_model = tf.estimator.DNNClassifier(hidden_units=[1000], n_classes=10, feature_columns=feature_columns)\n",
    "# input_fn_train = tf.estimator.inputs.pandas_input_fn(x=train_x, y=train_y, shuffle=False)\n",
    "# tf_model.train(input_fn=input_fn_train, steps=100)\n",
    "# tf_model.evaluate(input_fn=input_fn_train, steps=10)\n",
    "# #scores = cross_validate(tf_model, train_x, train_y, cv=k_fold, scoring='accuracy')   # throws an error\n",
    "# input_fn_predict = tf.estimator.inputs.pandas_input_fn(x=test_x, shuffle=False)\n",
    "# generator = tf_model.predict(input_fn=input_fn_predict)\n",
    "# output = [d['class_ids'][0] for d in generator]\n",
    "# submit = pd.DataFrame(data={'ImageId':test_id, 'Label':output})\n",
    "# submit.to_csv('nn_tensor_submit.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# neural network with keras\n",
    "# TODO reshape input\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Activation\n",
    "# keras_model = Sequential([\n",
    "#     Dense(input_dim=28*28, units=1000),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=10),\n",
    "#     Activation('softmax'),\n",
    "# ])\n",
    "# keras_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "# keras_model.fit(train_x.values, train_y.values, epochs=10, batch_size=100)\n",
    "# loss, metrics = keras_model.evaluate(train_x.values, train_y.values)\n",
    "# print(metrics)\n",
    "# output = keras_model.predict_classes(test_x.values)\n",
    "# print('\\n', output[:10])\n",
    "# submit = pd.DataFrame(data={'ImageId':test_id, 'Label':output})\n",
    "# submit.to_csv('nn_keras_submit.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageId,Label\r\n",
      "1,2\r\n",
      "2,0\r\n",
      "3,9\r\n",
      "4,9\r\n",
      "5,3\r\n",
      "6,7\r\n",
      "7,0\r\n",
      "8,3\r\n",
      "9,0\r\n"
     ]
    }
   ],
   "source": [
    "!head svm_submit.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "digit.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
